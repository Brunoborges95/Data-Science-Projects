{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Data Science Small Test - HIAE</h1></center>\n",
    "\n",
    "This is a small test to check the basic understand of machine learning developed by HIAE.\n",
    "Please do not spend too much time in it.\n",
    "<ol>\n",
    "    <li>Build a classification problem, using the columns $x$, $y$ and $z$, trying to classify the label\n",
    "column.\n",
    "        <ol type=\"a\">\n",
    "            <li>Segregate a test and training frame.</li>\n",
    "            <li>Use a GLM or Logistic Regression model and show the results</li>\n",
    "            <li>Use other method of your choice to handle the problem</li>\n",
    "            <li>Compare and comment the results on the models used from b) and c)</li>\n",
    "        </ol>\n",
    "    </li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> \n",
    "Importing all necessary libraries </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd #database manipulation\n",
    "import numpy as np #array manipulation\n",
    "from sklearn.model_selection import train_test_split #split the database\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression classifier\n",
    "from sklearn import metrics #metrics to evalueta models\n",
    "from sklearn.preprocessing import StandardScaler #normalization\n",
    "from sklearn.model_selection import RandomizedSearchCV #hyperparameters optimization\n",
    "import seaborn as sns #visualization library\n",
    "import warnings #avoid warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> \n",
    "Importing the database </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>326.488285</td>\n",
       "      <td>188.988808</td>\n",
       "      <td>-312.205307</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-314.287214</td>\n",
       "      <td>307.276723</td>\n",
       "      <td>-179.037412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-328.208910</td>\n",
       "      <td>181.627758</td>\n",
       "      <td>446.311062</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-148.658890</td>\n",
       "      <td>147.027947</td>\n",
       "      <td>-27.477959</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-467.065931</td>\n",
       "      <td>250.467651</td>\n",
       "      <td>-306.475330</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-23.863985</td>\n",
       "      <td>-44.084565</td>\n",
       "      <td>-276.796280</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3.660812</td>\n",
       "      <td>-252.599973</td>\n",
       "      <td>-445.044071</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>405.406480</td>\n",
       "      <td>124.734595</td>\n",
       "      <td>482.317678</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-467.877206</td>\n",
       "      <td>-49.022047</td>\n",
       "      <td>-340.056094</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>343.457737</td>\n",
       "      <td>142.910428</td>\n",
       "      <td>10.563133</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           x           y           z  label\n",
       "0           0  326.488285  188.988808 -312.205307    0.0\n",
       "1           1 -314.287214  307.276723 -179.037412    1.0\n",
       "2           2 -328.208910  181.627758  446.311062    1.0\n",
       "3           3 -148.658890  147.027947  -27.477959    1.0\n",
       "4           4 -467.065931  250.467651 -306.475330    1.0\n",
       "5           5  -23.863985  -44.084565 -276.796280    1.0\n",
       "6           6    3.660812 -252.599973 -445.044071    1.0\n",
       "7           7  405.406480  124.734595  482.317678    1.0\n",
       "8           8 -467.877206  -49.022047 -340.056094    0.0\n",
       "9           9  343.457737  142.910428   10.563133    0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPoints = pd.read_csv(\"df_points.txt\", delimiter=\"\\t\")\n",
    "dfPoints.head(10) # displays the first 10 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Normalization with the StandardScaler method </h3>\n",
    "Normalization is an important step for data preprocessing. Some machine learning models can behave badly and have low accuracy if standardization is not applied. The goal is to leave all database on the normal scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS=StandardScaler() #normalization using standarscaler method\n",
    "dfPoints['x'] = RS.fit_transform(dfPoints['x'].values.reshape(-1, 1))\n",
    "dfPoints['y'] = RS.fit_transform(dfPoints['y'].values.reshape(-1, 1))\n",
    "dfPoints['z'] = RS.fit_transform(dfPoints['z'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Selecting the features and the class of database </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dfPoints[['x', 'y', 'z']], dfPoints[['label']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the database is balanced, that is, if the points of the class are in the same proportion. Analyzing the graph confirms that the class is in fact balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0: 49.73 % of datapoints\n",
      "label 1: 50.27 % of datapoints\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25438c925c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('label 0:', round(\n",
    "        y['label'].value_counts()[0]/len(dfPoints)*100, 2), '% of datapoints')\n",
    "print('label 1:', round(\n",
    "        y['label'].value_counts()[1]/len(dfPoints)*100, 2), '% of datapoints')\n",
    "sns.countplot(\"label\",data=dfPoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Train and Test split </h3>\n",
    "Division between training and testing, in the proportion of 30% on the test basis. It avoids overffiting, due to the model training and adjusting the data on different bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains - 70%. Test - 30% \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression </h3>\n",
    "We can understand logistic regression as the analog of linear regression for classification problems. This type of problem arises when we want to categorize some variable by classes (usually two classes).\n",
    "In this step, we adjust the model on the training base.\n",
    "\t\n",
    "<a href=\"https://medium.com/@hpsuresh12345/logistic-regression-60694a973bee\">\n",
    "         <img alt=\"Qries\" src=\"https://miro.medium.com/max/1428/1*Vd9ZTC1zWJPtV7iXPMJk1Q.png\"\n",
    "         width=400\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression. penalty l2 regularization, tolerance for stopping criteria = 10^-4, C=1\n",
    "clf_lr = LogisticRegression(penalty='l2', tol=0.0001, C=1.0)\n",
    "#fitting the train data\n",
    "clf_lr.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Metrics </h3>\n",
    "There are many metrics useful for evaluating classification algorithms. Some of the most important are:\n",
    "<ol>\n",
    "<li><b>Accuracy</b>: \n",
    "The most used, basically measures the average classifier performance. It is the number of correct predictions made by the model over all types of predictions made</li>\n",
    "<li><b>Precision</b>: Measures the percentage of hits between observations rated positive</li>\n",
    "<li><b>Recall</b>: \n",
    "Measures the percentage of positive observations that were correctly classified</li>\n",
    "<li><b>F1</b>: \n",
    "This metric is a balance between recall and precision, using the harmonic mean of these metrics: $$F_{1}=\\frac{2*precision*recall}{precision+recall}$$</li> \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.57\n",
      "The precision score is: 0.56\n",
      "The recall score is: 0.68\n",
      "The F1 score is: 0.61\n"
     ]
    }
   ],
   "source": [
    "prediction_lr = clf_lr.predict(X_test) #predict the test data\n",
    "accuracy_lr = metrics.accuracy_score(y_pred=prediction_lr, y_true=y_test) #accuracy score\n",
    "precision_lr = metrics.precision_score(y_pred=prediction_lr, y_true=y_test) #precision score\n",
    "recall_lr = metrics.recall_score(y_pred=prediction_lr, y_true=y_test) #recall score\n",
    "F1_score_lr = metrics.f1_score(y_pred=prediction_lr, y_true=y_test) #F1 score\n",
    "print('The accuracy score is: %.2f' % accuracy_lr)\n",
    "print('The precision score is: %.2f' % precision_lr)\n",
    "print('The recall score is: %.2f' % recall_lr)\n",
    "print('The F1 score is: %.2f' % F1_score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Result - Logistic Regression Classifier </h3>\n",
    "If we simply classify the instances randomly, 50% accuracy would be expected. Analyzing the result above, we can see that the performance of the logistic regression model is poor, indicating underfitting. How accuracy is close to a random classifier, which does not justify the implementation of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random Forest Classifier </h3> \n",
    "In a simplified way, the random forest algorithm creates several decision trees and combines them to obtain a more accurate and more stable prediction. The Random Forest algorithm has several hyperparameters that need to be configured to optimize performance. We will use the RandomizedSearchCV method to find the best hyperparameters in the model.\n",
    "<a href=\"https://medium.com/@ar.ingenious/applying-random-forest-classification-machine-learning-algorithm-from-scratch-with-real-24ff198a1c57\">\n",
    "         <img alt=\"Qries\" src='https://miro.medium.com/max/1170/1*58f1CZ8M4il0OZYg2oRN4w.png'\n",
    "         width=500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting the Random Forest algorithm with optimized hyperparameters in the training base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()\n",
    "clf_RF = RandomizedSearchCV(RF, random_grid, random_state=42).fit(X_train,y_train)\n",
    "prediction_RF = clf_RF.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is: 0.80\n",
      "The precision score is: 0.80\n",
      "The recall score is: 0.80\n",
      "The F1 score is: 0.80\n"
     ]
    }
   ],
   "source": [
    "prediction_RF = clf_RF.predict(X_test)\n",
    "accuracy_RF = metrics.accuracy_score(y_pred=prediction_RF, y_true=y_test)\n",
    "precision_RF = metrics.precision_score(y_pred=prediction_RF, y_true=y_test)\n",
    "recall_RF = metrics.recall_score(y_pred=prediction_RF, y_true=y_test)\n",
    "F1_score_RF = metrics.f1_score(y_pred=prediction_RF, y_true=y_test)\n",
    "print('The accuracy score is: %.2f' % accuracy_RF)\n",
    "print('The precision score is: %.2f' % precision_RF)\n",
    "print('The recall score is: %.2f' % recall_RF)\n",
    "print('The F1 score is: %.2f' % F1_score_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Result - Random Forest </h3>\n",
    "As a result, we can see a significant improvement in the performance of the Random Forest algorithm in all the metrics used in comparison with the Logistic Regression algorithm. <b>The random forest model was able to correctly classify 80% of the test base instances, that is, it is able to correctly predict 80% of the class of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
